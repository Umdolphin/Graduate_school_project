---
title: 통계밥법론 Chapter8 & Chapter9 실습코드
author: 202140191 엄태훈
date: 2021-05-22(SAT)
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Chap8 Linear Regression by Least Squares

우리는 일상에서 수많은 일들을 경험하면서 살아간다. 이러한 경우, 인과관계는 하나의 원인이 하나의 결과에 영향을 미치는 것을 의미한다. 예를 들어, 소득이 높아질수록 세금을 많이 낸다거나 하루 총 칼로리가 높아질수록 몸무게가 커진다 등 우리는 수많은 인과관계 안에서 살아가고 있다.  

**회귀분석**은 이렇게 관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한뒤 적합도를 측정해 내는 분석 방법이다.   
시간에 따라 변화하는 데이터나, 어떤 영향, 인과관계의 모델링 등의 통계적인 예측에 이용될 수 있다.  

**단순회귀분석(Linear Regression)**은 하나의 독립변수와 종속변수를 이용하여 회귀분석을 진행하는 것을 말한다.   

**독립변수**는 종속변수에 영향을 주는 변수를 의미하고 즉, 원인을 나타내는 변수이고 **종속변수**는 독립 변수에 의해 영향을 받는 변수로 결과를 나타내는 변수이다.  

이번 챕터에서는 통계에서 가장 중요하게 여기는 분석방법 중 하나인 회귀분석에 대해서 알아본다.  

다양한 회귀 중에서도, 최소제곱법을 통한 선형회귀에 대해서 배워본다.  



## 8.2 Example-Body Fat Data

### 8.2.2 Data Desctription

```{r}
library(HH)
data(fat)
```

**fat** 데이터의 변수는 다음과 같다.  
* bodyfat: Siri의 방정식을 이용한 체지방 비율  
* abdomin: 복부 둘레
* biceps: 확장된 이두근 둘레


```{r}
splom(~fat,main="Fat data")
```

**fat** 산점도 행렬을 그리면 위와 같다.  
양의 상관관계를 가지고 있는 몇몇 변수가 보이는 것을 알 수 있다.  

## 8.3 Simple Linear Regression

### 8.3.1 Algebra

```{r}
A <- regrresidplot(fat$abdomin, fat$bodyfat, fit.line=FALSE,
                   xlim=c(70,185), ylim=c(0,50))

B <- regrresidplot(fat$abdomin, fat$bodyfat,
                   xlim=c(70,185), ylim=c(0,50), resid.plot="line")

C <- regrresidplot(fat$abdomin, fat$bodyfat,
                   xlim=c(70,185), ylim=c(0,50), resid.plot="square")

fat$shallow <- 20 + .1*fat$abdomin
fat.shallow.lm <- lm(shallow ~ abdomin, data=fat)

D <- regrresidplot(fat$abdomin, fat$bodyfat,
                   xlim=c(70,185), ylim=c(0,50), resid.plot="line",
                   lm.object=fat.shallow.lm)

E <- regrresidplot(fat$abdomin, fat$bodyfat,
                   xlim=c(70,185), ylim=c(0,50), resid.plot="square",
                   lm.object=fat.shallow.lm)

ALL <-
  update(c(C, E, A, B, D, layout=c(3,2)),
         skip=c(TRUE, rep(FALSE, 5)),
         scales=list(alternating=FALSE),
         between=list(x=2, y=2),
         xlab="abdomin", ylab="bodyfat",
         xlab.top=c("\n",
                    "least-squares fit:\ny = -28.56 + .505 x",
                    "too shallow:\ny = 20 + .1x"),
         ylab.right=list(c("squared\nresiduals","residuals"), rot=0))
ALL
```

fat 데이터에 대한 잔차를 그래프로 표현하였다.  
첫 번째 행 패널은 잔차, 두 번째 행 패널은 표준화된 잔차를 의미한다.  
첫 번째 행 패널의 두 번째 그림은 최소제곱법을 통해 잔차를 구한 그림을 나타낸다.  

### 8.3.3 Calculations

R에서의 선형회귀분석은 내장함수인 `lm`함수를 이용하여 분석을 진행할 수 있다.  

```{r}
data(fat)
fat.lm <- lm(bodyfat~abdomin,data=fat)
anova(fat.lm)
summary(fat.lm)
```

선형회귀분석 결과, **abdomin**변수의 유의확률이 유의수준 0.05보다 작으므로 유의한 변수임을 알 수 있다.  
선형회귀식 또한 살펴볼 수 있다.  

```{r}
par(mfrow=c(2,2))
plot(fat.lm)
```


잔차분석 결과, 모델의 선형성이 어긋나고 등분산성이 만족하지 않는 것처럼 보인다.  
또한, 12번, 36번, 39번 데이터가 이상치임을 알 수 있다.  
특히, 39번 데이터는 이상치 중에서도 모델에 심각한 영향을 끼치는 이상치로 보인다.  

```{r}
par(mfrow=c(2,3))
plot(fat.lm,which=1:6)
```

`which`옵션을 이용해 잔차분석에 대한 추가적인 그래프를 더 볼 수 있다.  

```{r}
B <- regrresidplot(fat$abdomin, fat$bodyfat,
                   ylim=c(0,50), resid.plot="line")

F <- regrresidplot(fat$abdomin, fat$bodyfat,
                   ylim=c(0,50), resid.plot="line",
                   lm.object=lm(bodyfat ~ 1, data=fat))

update(c(F, B, layout=c(2,1)), between=list(x=1),
       xlab="abdomin", ylab="bodyfat",
       scales=list(alternating=FALSE),
       xlab.top=c("Variance about\nmean of y", "Variance about\nleast-squares line"))
```

첫 번째 패널은 표본평균 y와 관측값 y에 대한 잔차를 나타낸 그래프이다.   
두 번째 패널은 최소제곱법을 이용한 잔차를 나타낸 그래프이다. (관측값 - 회귀선)의 제곱의 합  


```{r}
library("lattice")

bWA <- read.table(text="
 color   x       y
 red	1	6
 blue	2	2
 green	3	10
 orange	4	5
 brown	5	18
 purple	6	12
 ", header=TRUE, stringsAsFactors=FALSE)

betaWeightedAverageLattice <-
   function(x, y,
            xbar=mean(x), ybar=mean(y),
            beta1.hat, beta0.hat,
            col=seq(length=length(x))+1,
            color.summary=1,
            summary=TRUE,
            summary.text=TRUE,
            cex=1.5, pch=19,
            ...) {
       if (missing(beta1.hat) || missing(beta0.hat)) {
             beta.hat <- coef(lm(y ~ x))
             beta1.hat <- beta.hat[2]
             beta0.hat <- beta.hat[1]
           }
         xyplot(y ~ x, col=col,
                             xbar=xbar,
                             ybar=ybar,
                             beta1.hat=beta1.hat,
                             beta0.hat=beta0.hat,
                             col=col,
                             color.summary=color.summary,
                             summary=summary,
                             summary.text=summary.text,
                             cex=cex, pch=pch,
                             ...,
                             panel=function(x, y, ...) {
                                 panel.points(x=xbar, y=ybar, pch=8, cex=2, lwd=2, col=color.summary)
                                 panel.axis("bottom", at=xbar, labels=expression(bar(x)), rot=0, outside=TRUE)
                                 panel.axis("bottom", at=xbar, labels="")
                                 panel.axis("top", at=xbar, labels="")
                                 panel.axis("top", at=xbar, labels="", outside=TRUE)
                                 panel.axis("left", at=ybar, labels=expression(bar(y)), outside=TRUE)
                                 panel.axis("left", at=ybar, labels="")
                                 panel.axis("right", at=ybar, labels="")
                                 panel.axis("right", at=ybar, labels="", outside=TRUE)
                                 if (summary)
                                    panel.abline(a=beta0.hat, b=beta1.hat, lwd=2, col=color.summary)
                                 if (summary.text) {
                                     ## panel.text(x=xbar-1, y=ybar+2,
                                       ##            expression((bar(x) * ',' * bar(y))),
                                       ##            col=color.summary, cex=2)
                                       panel.text(x=6.6, y=14.2,expression(y = hat(beta)[0] + hat(beta)[1] * x),
                                                                              col=color.summary, cex=1.4,
                                                                              xpd=NA, adj=0)
                                     panel.text(x=8, y=14.2,paste("  =", round(beta0.hat, 3), "+", 
                                                                  round(beta1.hat, 3), "x"),col=color.summary,
                                                cex=1.4,xpd=NA, adj=0)
                                   }
                                panel.segments(x, y,    x,    ybar, col=col, lty=2, lwd=1)
                                 panel.segments(x, ybar, xbar, ybar, col=col, lty=2, lwd=1)
                                 panel.segments(x, y,    xbar, ybar, col=col, lty=1, lwd=3)
                               },
                             par.settings=list(clip=list(panel=FALSE))
                             )
   }

## betaWeightedAverageLattice(bWA$x, bWA$y, col=bWA$color, xlim=c(-.2, 12.2))

dx <- bWA$x-mean(bWA$x)
dy <- bWA$y-mean(bWA$y)
betas <- dy / dx
wts <- dx^2 / sum(dx^2)

Six <- do.call(c,lapply(1:nrow(bWA),function(i)
                                  betaWeightedAverageLattice(bWA$x[i],bWA$y[i],col=bWA$color[i],xbar=mean(bWA$x),
                                                             ybar=mean(bWA$y),summary=FALSE,xlim=c(0,7),ylim=c(0,20), xlab=NULL, ylab=NULL,summary.text=FALSE)))

 print(position=c(0, .6, 1, 1), more=TRUE,
        update(Six,
                         strip=strip.custom(factor.levels=paste(
                                                "slope = ", round(betas, 3), "\n",
                                                "weight = ", round(wts, 3),
                                                sep="")
                             ),
                         par.strip.text=list(lines=2.5, cex=.7),
                         scales=list(alternating=0),
                         between=list(x=1, y=1),
                         as.table=TRUE,
                         layout=c(6,1)
                         )
               )

beta.hat <- coef(lm(y ~ x, data=bWA))
print(position=c(.2, 0, .8, .6), more=FALSE,
         update(betaWeightedAverageLattice(bWA$x, bWA$y, col=bWA$color, xlim=c(-2, 9), summary.text=FALSE, xlab=NULL, ylab=NULL),
                         strip=strip.custom(factor.levels=paste("slope =", as.character(round(beta.hat[2], 3)))))
         )
```


기울기와 가중치에 따른 직선의 변화를 살펴볼 수 있다.  

### 8.3.5 New Observations

```{r}
h <- hat(model.matrix(fat.lm))

pred <- predict(fat.lm, se.fit=TRUE)

res <- resid(fat.lm)

# anova(fat.lm)['Residuals','Mean Sq']를 지정하면 anova에 저장된 MSE값을 객체에 저장할 수 있다.  
sigma.hat.sequare <- anova(fat.lm)["Residuals","Mean Sq"]

fat.predvalues <- data.frame("y=bodyfat"=fat$bodyfat,"x=abdomin"=fat$abdomin, h=h, mu.hat=pred$fit, e=res, var.mu.hat=h*sigma.hat.sequare, var.resid=(1-h)*sigma.hat.sequare, se.fit=sqrt(h*sigma.hat.sequare),se.resid=sqrt((1-h))*sigma.hat.sequare)

fat.predvalues[1:3,1:7]

## linear identity
all.equal(rowSums(fat.predvalues[,c("mu.hat","e")]),fat$bodyfat,check.names=FALSE)
```

```{r}
## quadratic identity
(SSqReg <- sum((fat.predvalues$mu.hat-mean(fat$bodyfat))^2))

(SSqRes <- sum(res^2))

(SSqTot <- sum((fat$bodyfat - mean(fat$bodyfat))^2))

all.equal(SSqReg + SSqRes, SSqTot)
```


**SST,SSR,SSE**를 ``fat``데이터를 이용하여 직접 계산하였다.   
그 후, R의 `all.equal`함수를 이용하여 SST(총변동) = SSR + SSE이 식대로 정말 같은지 확인하였다.  
결과값은 TRUE로, 주어진 식이 성립하는 것을 알 수 있다.  


```{r}
set.seed(42)
old.data <- data.frame(y=rnorm(50),x1=rnorm(50),x2=rnorm(50),x3=rnorm(50))

example.lm <- lm(y~x1+x2+x3,data=old.data)

(example.coef <- coef(example.lm))

(new.data <- data.frame(x1=3,x2=2,x3=45))

predict(example.lm,newdata = new.data,se.fit=TRUE,interval="confidence")

predict(example.lm,newdata=new.data,se.fit=TRUE,
        interval="prediction")

c(1,data.matrix(new.data)) %*% example.coef
```

난수를 통해 회귀식을 세우고 새로운 데이터에 대해서 선형회귀식을 적합시켰다.  
`predict`함수를 통해 새로운 데이터에 대한 예측을 진행할 수 있다.  
`se.fit` 옵션을 통해 잔차를 계산할 수 있고 `interval`옵션을 통해 신뢰구간을 구할 수 있다.  

***

`ci.plot`함수를 사용하면 앞선 분석을 통해 얻었던 관찰값, 회귀식, 신뢰구간 등을 시각적으로 나타낼 수 있다.  

```{r}
ci.plot(fat.lm)
```

`lmplot`함수를 사용하면 회귀모형을 진단하기 위한 정보를 얻을 수 있다.  

```{r}
lmplot(fat.lm)
```

```{r}
colB <- likertColor(2)[2]
pp <- ppoints(101)
x <- qnorm(pp)
xyplot(pp ~ x, pch=19, xlab.top=list("Cumulative Distribution of N(0,1)\n", cex=1.3), col=colB,
       xlab=list(cex=1.3), ylab=list(cex=1.3), ylab.right=list(cex=1.3),
       scales=list(x=list(alternating=FALSE, tck=c(1,0))))

n <- nrow(fat)
f <- (1:n)/n
diag2a <- xyplot(f ~ sort(predict(fat.lm)), pch=19,
                 main="empirical cdf of\nfitted values\n", col=colB)
diag2b <- xyplot(f ~ sort(resid(fat.lm)), pch=19,
                 main="empirical cdf of\nresiduals\n", col=colB)

update(c(diag2a, diag2b, layout=c(2,1)),
       xlab=list(c(diag2a$xlab, diag2b$xlab), cex=1.3),
       xlab.top=list(c(diag2a$main, diag2b$main), cex=1.3),
       ylab=list(cex=1.3), ylab.right=list(cex=1.3),
       main=NULL,
       scales=list(x=list(alternating=FALSE, tck=c(1,0))),
       between=list(x=1))

mean.bodyfat <- mean(fat$bodyfat)
diag3a <- xyplot(f ~ sort(predict(fat.lm) - mean.bodyfat), pch=19,
                 main="empirical cdf of\ncentered fitted values\n", col=colB)
diag3b <- xyplot(f ~ sort(resid(fat.lm)), pch=19,
                 main="empirical cdf of\n residuals\n", col=colB)
tmp3 <- update(c(diag3a, diag3b, layout=c(2,1)),
               xlab=list(c(paste0(diag3a$xlab, "       "), diag3b$xlab), cex=1.3),
               xlab.top=list(c(diag3a$main, diag3b$main), cex=1.3),
               ylab=list(cex=1.3), ylab.right=list(cex=1.3),
               main=NULL,
               scales=list(x=list(alternating=FALSE, tck=c(1,0))),
               between=list(x=1))
tmp3c <-
  combineLimits(as.matrix(row=TRUE, tmp3), margin.x=1)
tmp3c

diag4a <- xyplot(sort(predict(fat.lm) - mean.bodyfat) ~ f, pch=19,
                 main="transposed empirical cdf of\ncentered fitted values", col=colB)
diag4b <- xyplot(sort(resid(fat.lm)) ~ f, pch=19,
                 main="transposed empirical cdf of\nresiduals", col=colB)

tmp4 <- update(c(diag4a, diag4b, layout=c(2,1)),
               xlab.top=list(c(diag4a$main, diag4b$main), cex=1.3),
               xlab=list(cex=1.3), ylab=list(cex=1.3),
               main=NULL,
               ylab.right=list(diag4b$ylab, cex=1.3),
               scales=list(x=list(alternating=FALSE, tck=c(1,0)), y=list(rot=0)),
               between=list(x=1))
combineLimits(as.matrix(row=TRUE, tmp4))

```

회귀모형에 대한 empricial distribution을 plot을 통해 나타내었다.  


```{r}
x <- rnorm(100)
e <- rnorm(100)

y1 <- sqrt(.1) * x + sqrt(1-.1) * e
y5 <- sqrt(.5) * x + sqrt(1-.5) * e
y9 <- sqrt(.9) * x + sqrt(1-.9) * e

rr <- data.frame(x, e, y1, y5, y9)
ThreeR2 <-
  c(
    diagplot5new(lm(y1 ~ x, data=rr), ylim=c(-3.2, 3.2)),
    diagplot5new(lm(y5 ~ x, data=rr), ylim=c(-3.2, 3.2)),
    diagplot5new(lm(y9 ~ x, data=rr), ylim=c(-3.2, 3.2))
  )
## ThreeR2
TM <- update(matrix.trellis(ThreeR2, byrow=TRUE, nrow=3, ncol=2), between=list(y=1))
## TM

TMn <- update(TM,
              xlab.top=c(expression(hat(y)-bar(y)), expression(y-hat(y))),
              ylab="", ylab.right=NULL)
## TMn

print(position=c(0, 0, .4, 1), more=TRUE,
      update(strip=FALSE, xlab.top=expression(phantom(hat(y))*y*phantom(hat(y))),
             ylab=NULL,
             ylab.right=list(c(
               expression(R^2==.1),
               expression(R^2==.5),
               expression(R^2==.9)), rot=0),
             ylim=c(-3.2, 3.2),
             xyplot(y1 + y5 + y9 ~ x, data=rr, outer=TRUE, pch=19,
                    panel=function(...) {
                      panel.lmline(...)
                      panel.points(...)
                    },
                    layout=c(1,3),
                    scales=list(alternating=FALSE), between=list(y=1))
      ))

print(position=c(.39, 0, 1, 1), more=FALSE,
      update(TMn, ylim=c(-3.2, 3.2))
)
```

임의의 난수를 생성하여 산점도를 살펴보고 그에 따른 결정계수를 구해보았으며, empricial distribution을 오른쪽 패널에 나타내었다.  


***

# Summary of Chapter8

* **회귀분석**이란 인과관계를 맺고 있는 변수들간의 함수 관계를 규명하여 최적회귀모형을 도출하기위한 통계적 분석방법이다. 다시 말해서, 우리가 가지고 있는 원인변수가 결과변수에 얼만큼의 영향을 미치고 원인변수를 통해 결과변수를 예측하는 것을 목표로한다.

* **단순회귀분석**은 하나의 독립변수와 하나의 종속변수를 이용하여 회귀모형에 적합시키는 것을 말한다. **종속변수**는 우리가 예측하고자 하는 변수로 인과관계에서 결과의 의미를 가지고 있는 변수를 말하며, **독립변수**는 종속변수에 대해 영향을 미치는 변수를 말하며 원인의 의미를 가지고 있는 변수이다.

* **최소제곱법**은 근사적으로 구하려는 해와 실제 해의 오차의 제곱의 합이 최소가 되는 해를 구하는 방식이다. 일반적으로 단순회귀분석에서는 이러한 최소제곱법을 이용하여 회귀모형에 대한 가장 적합한 직선을 찾게 된다.

* 회귀분석은 일반적으로 4가지의 기본 가정을 가지고 있는데 ANOVA와 동일한 기본 가정인 **독립성**, **등분산성**, **정규성**과 **선형성**의 가정을 가지게 된다. **선형성은** 종속변수와 독립변수간 선형성을 만족한다는 가정을 말한다. 이러한 가정들은 변수들을 모형에 적합시킨 후, 잔차분석을 통해 기본가정이 성립하는지 확인할 수 있다.

* **결정계수**는 독립변수와 종속변수를 통해 우리가 추정한 회귀 모형이 얼마 만큼 적합한지를 나타내는 척도로, 최대값은 1이며 높을수록 적합도가 높다는 의미이다.

* R에서는 `lm`함수를 이용하여 회귀분석을 쉽게 진행할 수 있다. `lm`의 기본적인 Formula는 (종속변수 ~ 독립변수,data)의 형태로 지정하여 분석을 할 수 있다. `lm`을 통해 회귀모형을 만들게 되면, 독립변수가 유의한지, 주어진 회귀모형의 적합도와 회귀모형이 유의한지, 잔차분석 등 많은 유용한 정보를 확인할 수 있다.  

***


***

# Chapter 9 Multiple Regression - More than One Predictor

앞선 챕터에서 우리는 하나의 독립변수를 가지는 **단순선형회귀**분석에 대해서 알아보았다.  
정확히 하나의 결과에만 영향을 미치는 독립변수가 하나만 있다면 예측력도 좋고 간단한 모델을 만들 수 있을 것이다.  

하지만, 우리의 일상에서는 하나의 결과에 대하여 수많은 원인을 갖고 있는 경우가 대부분이다.  
따라서, 이러한 경우에는 하나의 독립변수만을 사용하는 **단순선형회귀분석**을 이용할 수가 없다.  

독립변수가 하나가 아닌 두 개 이상의 독립변수를 갖는 경우, **다중회귀분석**을 이용하여 회귀모형을 만들어야 한다.  
**다중회귀분석**은 하나의 종속변수에 대하여 독립변수가 두 개이상 있을 때 사용하는 분석기법으로, 종속변수에 영향을 미치는 유의한 독립변수를 찾을 때, 유용하다.  

이번 챕터에서는 **다중회귀분석**에 대하여 알아보도록 한다.  



## Multiple Regression - Two X Analysis

`car`패키지의 `scatter3d`함수를 이용하여 3차원의 산점도를 그릴 수 있다.  

```{r}
fat2.resid <- resid(lm(bodyfat ~ abdomin + biceps, data=fat))
car::scatter3d(bodyfat ~ abdomin + biceps, data=fat, fit="linear",
               residuals="squares",
               bg="white", axis.scales=TRUE, grid=TRUE, ellipsoid=FALSE,
               square.color = "gray80", surface.col="#a6cafe",
               surface.alpha=.3, sphere.size=.7,
               point.col=c("red","green")[1+(fat2.resid >= 0)])
```



```{r}
fat2.lm <- lm(bodyfat ~ abdomin + biceps, data=fat)
anova(fat2.lm)

summary(fat2.lm)
```

`fat`데이터에 대해서 다중회귀분석을 진행하였다.    
회귀식에 사용된 **abdomin,biceps**변수 모두 유의확률이 유의수준 0.05보다 작은 것으로 보아 유의한 변수임을 확인할 수 있다.  

***


**fat2.lm**의 회귀모형을 진단하기 위해 `lmplot`함수를 사용하였다.  


```{r}
lmplot(fat2.lm)
```


```{r}
par(mfrow=c(2,2))
plot(fat2.lm)
```

잔차분석 결과, 36,39,41번 데이터가 이상점인 것을 확인할 수 있었다.  
선형성과 정규성, 등분산성은 약간 만족하지 않는 것 처럼 보인다.  

## 9.5 Example - Albuquerque Home Price Data

### 9.5.2 Data Description

```{r}
data("houseprice")
splom(~houseprice)
```

**houseprice**데이터의 변수별 관계를 살펴보기 위해 산점도 행렬을 그려보았다.  
**price-sqft**,**price-taxes**는 양의 상관관계를 가지고 있는 것 처럼 보인다.  

## 9.6 Partial F-Tests

```{r}
houseprice.lm2 <- lm(price ~ sqft + taxes + custom + corner, data=houseprice)

anova(houseprice.lm2)

summary(houseprice.lm2)
```

**price**를 종속변수로 하고 **sqft, taxes, custom, corner **을 독립변수로 하는 회귀분석을 진행하였다.  
회귀분석 결과, 모든 변수의 유의확률이 유의수준 0.05보다 작으므로 모든 독립변수는 유의하다.  
또한, 회귀모형의 P-value가 0.05보다 작으므로 회귀모형은 유의한 모형임을 확인할 수 있다.  


```{r}
library(dplyr)
house_dat <- houseprice %>% 
  select(price,sqft,taxes)
houseprice$group <- 
ifelse(houseprice$corner==0,"middle","corner")

splom(~house_dat|houseprice$group,pch=c(2,1),col=c("#7685c8","#E16A92"),groups=houseprice$custom,key=list(text=list(c("regular","custom")),
      points=list(pch=c(2,1),col=c("#7685C8","#E16A92"))))

```

그룹에 따른 데이터 탐색을 위해 회귀모형에 사용한 연속형 변수에 대한 산점도 행렬을 그려보았다.  
산점도 행렬은 **corner**변수에 따라 구분하였고 **custom**변수에 따라 포인터의 형태와 색깔을 다르게 지정하였다.  
**regular**일 때보다, **custom**일 떄 연속형 변수들이 조금 더 높은 값을 가지는 것을 알 수 있다.  


```{r}
houseprice.lm1 <- lm(price ~ sqft +taxes, data=houseprice)

anova(houseprice.lm1, houseprice.lm2)
```

기존 모델과 변수를 하나 제거한 모델의 **Anova**를 진행하였다.  
분석결과, 유의확률이 유의하게 나온 것을 알 수 있었고 이는 회귀모형간 평균차이가 있다는 것을 의미한다.  
즉, **Houseprice**의 회귀모형에서 **custom**변수 유무에따른 평균차이가 존재한 다는 것을 알 수 있다.  

## 9.7 Polynomial Models
```{r}
data(hardness)

hardness.lin.lm <- lm(hardness ~ density, data=hardness)

anova(hardness.lin.lm)

hardness.quad.lm <- lm(hardness ~ density + I(density^2),data=hardness)

anova(hardness.quad.lm)

coef(summary.lm(hardness.quad.lm))
```

**hardness**데이터를 이용하여 1차 회귀식과 2차 회귀식을 비교해보았다.  
1차, 2차 회귀식 모두 변수에 따른 평균 차이가 있음을 확인할 수 있었다.  
하지만, 계수를 확인해본결과, 절편과 **1차 density**는 유의하지 않은 것을 확인할 수 있다.  
여기서의 2차는 단순 2차식이 아닌 `I`함수를 이용하여 직교 2차를 이용하였다.  


```{r}
h2 <- data.frame(density=hardness$density, poly(hardness$density,2))

xyplot(X1 + X2 ~ density, data=h2)
```

이번에는 `poly`함수를 이용하여 단순 제곱을 구하여 다시 한 번 분석을 진행해본다.  
**density**에 대한 1차식, 2차식을 plot으로 나타내었다.  
파란점이 1차식, 빨간점이 2차식의 데이터를 나타낸다.  

***

`regrresidplot`함수를 통해 최소제곱법을 이용한 잔차의 계산 과정을 시각화하여 살펴볼 수 있다.  


```{r}
SQ <- regrresidplot(hardness$density, hardness$hardness, xlim=c(20, 85),
                    resid.plot="square")
QU <- regrresidplot(hardness$density, hardness$hardness, xlim=c(20, 85),
                    resid.plot="square", lm.object=hardness.quad.lm)
update(c(SQ, QU, layout=c(2, 1)), xlab="density", ylab="hardness",
       between=list(x=1), scales=list(alternating=FALSE))

```


```{r}
hardness.quad.orth.lm <- lm(hardness ~ density + h2$X2, data=hardness)
anova(hardness.quad.orth.lm)
coef(summary.lm(hardness.quad.orth.lm))
```

단순 제곱을 이용하여 분석을 진행한 결과, 변수에 따른 평균적인 차이가 있음을 알 수 있다.  
또한, 앞선 분석과 달리 **1차,2차,절편**의 모든 계수가 유의해진 것을 확인할 수 있다.  

## 9.8 Models Without a Constant Term

```{r}
data(fat)

## usual model with intercept
xy.int.lm <- lm(bodyfat ~ biceps, data=fat)
summary(xy.int.lm)

anova(xy.int.lm)
```

**fat**데이터에 대해서 회귀분석을 진행한 결과, 절편은 유의하지 않고 **biceps**는 유의한 변수임을 확인할 수 있다.  
또한, `anova`분석을 통해 **biceps**에 따라 평균 차이가 있음을 알 수 있다.  

```{r}
data(fat)

## model without a constant term
xy.noint.lm <- lm(bodyfat ~ biceps -1, data=fat)
summary(xy.noint.lm)

anova(xy.noint.lm)
```

유의하지 않은 절편을 제거하고 분석을 다시 진행한 결과, 이전 분석보다 회귀모형의 설명력과 유의확률이 더 좋아진 것을 알 수 있다.  


```{r}
library(lattice)
A <-
  xyplot(bodyfat ~ biceps, data=fat, pch=19, col=likertColor(2)[2],
         key=list(title="model",
                  space="right",
                  text=list(c("intercept", "no intercept")),
                  lines=list(lty=c(1,2), lwd=2),
                  col=c("black","red"),
                  border=TRUE))+
  layer(panel.abline(xy.int.lm, col="black", lty=1)) +
  layer(panel.abline(xy.noint.lm, col="red", lty=2))

B <-
  update(A, xlim=c(-5,46), ylim=c(-22,35)) +
  layer(panel.abline(h=0, v=0, col="gray40", lty=2))

c(A, B, layout=c(2,1))

```


`xyplot`을 이용하여 앞서 진행한 분석을 시각적으로 나타내었다.  


## 9.9 Prediction
```{r}
fat2.lm <- lm(bodyfat ~ abdomin + biceps, data=fat)

pi.fit <- predict(fat2.lm,
                  newdata=data.frame(abdomin=93:94,biceps=33:34),
                  se.fit=TRUE, interval="prediction")

ci.fit <- predict(fat2.lm, newdata=data.frame(abdomin=93:94,biceps=33:34),
                  se.fit=TRUE,interval="confidence")
```


`predict``함수를 이용하여 회귀식을 통해 예측을 진행해보았다.  
`interval`옵션을 이용하여 `prediction`을 입력하면 예측구간, `confidence`를 입력하면 신뢰구간에 대한 정보를 얻을 수 있다.  


## 9.10 Example - Longley Data

### 9.10.2 Data Description
```{r}
data(longley)
splom(~longley)
```

**longley**함수의 데이터 탐색을 위해 산점도 행렬을 그려보았다.  
대부분의 변수간 양의 상관관계가 존재하는 데이터임을 알 수 있다.  


```{r}
longley.lm <- lm(Employed ~. , data=longley)

summary(longley.lm)

anova(longley.lm)
vif(longley.lm)
```

**longley**의 모든 변수를 이용하여 회귀분석을 진행하였다.  
회귀모형 안에서, **절편,Unemployed,Armed.Forces,Year**의 변수가 유의한 변수임을 확인할 수 있었다.  
하지만, `vif`함수를 이용하여 다중공선성을 검사해본 결과, **Armed.Forces** 변수를 제외한 모든 변수들의 다중공선성이 매우 심각한 것을 확인할 수 있었다.  
따라서, 적합한 회귀모형을 찾기 위해서는 적절한 변수 선택이 필요한 것으로 보인다.  

## 9.12 Variable Selection

### 9.12.1 Manual Use of the Stepwise Philosophy

```{r}
longley3.lm <- lm(Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + Year, data=longley)

summary(longley3.lm)

anova(longley3.lm)
vif(longley3.lm)
```

**Population** 변수를 제거한 후, 다시 한 번 다중공선성 검사를 진행해본 결과, 여전히 **Armed.Forces** 변수를 제외한 변수에서 다중공선성이 있는 것을 확인할 수 있다.  

```{r}
longley4.lm <- lm(Employed ~ GNP + Unemployed + Armed.Forces + Year, data=longley)

summary(longley4.lm)

anova(longley4.lm)
vif(longley4.lm)
```

**GNP.deflator** 변수를 제거한 후에도 **Armed.Forces**변수를 제외한 변수들은 여전히 다중공선성이 있는 것처럼 보인다.  

```{r}
longley5.lm <- lm(Employed ~ Unemployed + Armed.Forces + Year, data=longley)

summary(longley5.lm)

anova(longley5.lm)

vif(longley5.lm)
```

**vif**지수가 제일 높은 **GNP** 변수를 제거한 결과, 남은 3개의 변수 모두 다중공선성이 없는 것을 확인할 수 있었다.  

### 9.12.3 Automated Stepwise Modeling of the Longley Data

```{r}
longley.subsets <-
  leaps::regsubsets(Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + Population + Year,
                    data=longley, nbest=2)

longley.subsets.Summary <- summaryHH(longley.subsets)

longley.subsets.Summary
```

`summaryHH`함수를 이용하여 변수선택에 따른 회귀모형의 성능지표 변화를 확인할 수 있다.  

```{r}
tmp <- (longley.subsets.Summary$cp <= 10)
longley.subsets.Summary[tmp,]
```

선별된 변수들 중, **cp**지수가 10보다 작은 변수선택 방법들만을 추출하였다.  

## 9.14 Example - U.S.Air Pollution Data

```{r}
data(usair)
splom(~usair)
```

**usair**변수에 대한 데이터 탐색을 진행하기 위해 `splom`을 이용하여 산점도 행렬을 나타내었다.  
변환을 통해 몇몇 변수에 대하여 데이터를 조금 더 퍼뜨릴 필요성이 있어 보인다.  

```{r}
library(dplyr)

usair$lnSO2 <- log(usair$SO2)
usair$lnmfg <- log(usair$mfgfirms)
usair$lnpopn <- log(usair$popn)

usair_tansform <- usair %>% 
  select(-SO2,-mfgfirms,popn)
```


변환이 필요한 변수들에 **log**변환을 진행하여 데이터를 조금 더 퍼뜨려주었다.  

```{r}
splom(~usair_tansform)
```

앞서 변환을 진행하기 전 산점도 행렬보다 상관관계가 보이는 변수들을 확인할 수 있다.  

```{r}
usair.regsubset <- leaps::regsubsets(lnSO2 ~ lnmfg+ lnpopn + precip + raindays + temp + wind, data=usair_tansform, nbest=2)

usair.subsets.Summary <- summaryHH(usair.regsubset)

tmp <- (usair.subsets.Summary$cp <= 10)

usair.subsets.Summary[tmp,]

```

`summaryHH`를 이용하여 **usair** 데이터에 대하여여 자동적으로 변수선택을 진행하고 그에 따른 회귀 성능지표의 변화를 살펴보았다.  



```{r}
plot(usair.subsets.Summary[tmp,], statistic='cp')
```


**cp**와 **Number of paramter**의 관계를 산점도로 나타내었다.  

## 9.15 Example - mtcars data

지금까지 배운 내용들을 토대로 mtcars 데이터를 통해 **multiple regression**을 적합시켜 보자.

```{r}
data(mtcars)
str(mtcars)
```

```{r}
head(mtcars,5)
```

mtcars의 데이터 변수들의 형태와 대략적인 구조를 살펴본다.

```{r}
pairs(mtcars)
```

`pairs`함수를 이용해 변수들의 관계를 살펴보기 위해 다중산점도 행렬을 그려보았다.  
우리가 target변수로 설정한 mpg와 다른 독립변수들은 양의 상관관계 혹은 음의 상관관계를 갖고있는 것 처럼 보인다.  

```{r}
colSums(is.na(mtcars))
```

`colSums`를 이용하여 결측치 검정을 진행한 결과, 데이터의 결측치는 확인되지 않았다.  

```{r}
mr <- lm(mpg~.,data=mtcars)
summary(mr)
```

```{r}
library(car)
vif(mr)
```


mtcars 데이터를 이용하여 다중회귀분석을 진행해보았다. 모형은 유의하고 적합도는 약 80%로 나온것을 확인할 수 있었다. 하지만, 대부분의 변수들의 유의확률보다 높아 유의하지 않았고 다중공선성이 존재하는 변수가 있는 것을 확인할 수 있었다.  
따라서, 변수선택법을 진행하여 최적의 변수들을 찾아볼 필요가 있다고 판단하였다.  

```{r}
step(mr,direction="forward")
```

```{r}
summary(lm(mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb,data=mtcars))
```

**전진선택법**을 이용하여 변수선택을 진행해본 결과, 모든 변수를 선택하는 것이 적합하다고 나왔다.

```{r}
step(mr,direction="backward")
```
```{r}
summary(lm(formula = mpg ~ wt + qsec + am, data = mtcars))
```

```{r}
vif(lm(formula = mpg ~ wt + qsec + am, data = mtcars))
```

**후진제거법**을 사용하여 변수선택을 진행한결과, **wt,qsec,am**변수가 선택되었고 이 변수들을 회귀모형에 적합시킨 결과, 모든 변수가 유의하고 결정계수 또한 이전보다 높아진 것을 확인할 수 있었다.  
또한, 다중공선성이 존재하는 변수들도 사라진 것을 알 수 있었다.  

```{r}
step(mr,direction="both")
```

```{r}
summary(lm(formula = mpg ~ wt + qsec + am, data = mtcars))
```

**stepwise**방법을 이용하여 변수 선택을 진행한결과, 후진제거법과 동일한 변수선택이 나왔다.  
이를 통해, 변수선택법을 이용함에 있어서는 **wt,qsec,am**변수를 통해 회귀모형을 만드는 것이 최적의 회귀모형임을 알 수 있었다.  


***

# Summary of Chapter9

* **다중회귀분석(Multiple Regression)**은 단순회귀분석과 달리, 독립변수가 두 개 이상인 회귀분석을 말한다. 독립변수가 하나가 아닌 두 개이상 사용되기 때문에 적절한 변수를 선택하고 변수마다 확실하게 이해를 하고 회귀모형에 적합하는 것이 좋다.

* 변수들을 다중회귀모형에 적합하기 전, 가장 좋은 방법 중 하나는 산점도 행렬을 통해 변수들간의 관계를 살펴보는 것이다. **산점도 행렬**은 변수 간 산점도를 행렬과 같이 한 공간안에 모두 나타내는 것을 말한다. **산점도 행렬**을 보게 되면, 변수들의 관계를 시각적으로 쉽게 파악할 수 있다.

* **다중회귀분석**은 많은 변수들을 고려하기 때문에 변수들 안에서 강한 상관관계가 나타날 수 있다. **다중공선성**은 독립변수들 간에 강한 상관관계가 나타나는 문제를 말하며, 이는 공분산을 높이게 되어 회귀모형의 적합도를 낮출 수도 있다. 따라서, 항상 다중회귀분석을 진행하기 전에, 독립변수 간 다중공선성을 파악하는 것이 필요하다. 

* 고려해야할 변수가 너무 많은 경우, **변수선택법**을 고려할 수 있다. **변수선택법**은 모형을 보다 더 잘 설명하는 변수들만을 골라서 최적의 회귀모형을 만드는 것을 말한다. **변수선택법**은 일반적으로 3가지의 선택법이 있다.

* 첫 번째는 **전진선택법**으로 변수의 개수를 하나씩 늘려나가면서 최적의 회귀모형을 찾아나가는 방법이다. 두 번째는 **후진제거법**으로 전체 변수를 모형에 적합시킨 뒤, 변수를 하나씩 제거해가며 최적의 회귀모형을 찾아나가는 방법이다. 마지막으로 **단계적선택법**은 변수를 하나씩 늘려가다가 중요하지 않은 변수가 선택되면 제거하고 다시 다른 변수를 추가하는 식으로 진행되는 방법이다. 일반적으로는 **단계적선택법(Stepwise)**방법을 많이 사용하지만, 모형의 목적과 데이터에 따라 적절한 변수선택법이 다를 수도 있으니 모든 방법을 고려해보는 것이 좋다.

* R에서 다중공선성은 `car`패키지의 `vif`함수를 통해 쉽게 확인할 수 있다. **vif**는 분산팽창요인이라고 말하며, 10이 넘는 경우 다중공선성이 있다고 말한다. 따라서, 다중공선성이 의심된다면 10이 넘는 변수들 중, 값이 큰 변수들부터 제거하여 회귀모형에 적합시키는 것이 좋다.

* 앞서, 단순회귀분석에서 우리는 회귀모형의 적합도를 파악하는데 결정계수를 사용하였다. 다중회귀분석의 적합도를 살펴볼 때에는 이러한 결정계수를 통해 적합도를 확인해서는 안 된다. 왜냐하면, 결정계수는 독립변수의 수가 늘어날수록 커지는 경향이 있기때문에 다중회귀분석에서는 적합도 측정 지표로 적합하지 않다. 따라서, 다중회귀분석에서는 결정계수가 아닌 수정된 결정계수, cp, BIC 등 다른 지표를 통해 적합도를 살펴보는 것이 좋다.


***


